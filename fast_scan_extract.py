# fast_scan_extract.py
# ---------------------------------------------------------
# ç‹¬ç«‹ç‰ˆï¼šæå–æ—¶é—´è½´ + æ—¶é—´åˆ†è¾¨å…‰è°± + èƒŒæ™¯å…‰è°±ï¼ˆæ— å¤–éƒ¨ JSONï¼‰
# ---------------------------------------------------------

import os
import numpy as np
import argparse
from collections import defaultdict

# ========= å†…ç½®èƒŒæ™¯å®šä½å‚æ•°ï¼ˆæ¥è‡ª bg_markers.jsonï¼‰ =========
BG_INTERVAL_BYTES = 9040  # æ¯æ¡èƒŒæ™¯å…‰è°±ä¹‹é—´çš„å­—èŠ‚é—´éš”
BG_MARKERS = [
    {"delta_to_payload": 336, "hex": "01 00 00 00 80 08 00 00"},
    {"delta_to_payload": 335, "hex": "00 00 00 80 08 00 00 02"},
    {"delta_to_payload": 334, "hex": "00 00 80 08 00 00 02 00"},
    {"delta_to_payload": 333, "hex": "00 80 08 00 00 02 00 00"},
    {"delta_to_payload": 332, "hex": "80 08 00 00 02 00 00 00"},
]
FRAME_MARKER_HEX = "c6 d7 cd bc b2 c9 d3 da"
DEFAULT_POINTS = 1024


# ========= å·¥å…·å‡½æ•° =========
def read_all_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()


def find_all(haystack: bytes, needle: bytes, max_hits=200000):
    out, st = [], 0
    while True:
        i = haystack.find(needle, st)
        if i == -1:
            break
        out.append(i)
        if len(out) >= max_hits:
            break
        st = i + 1
    return out


# ========= æ—¶é—´è½´æå– =========
def extract_time_axis(srs: bytes, frame_marker: bytes):
    positions = find_all(srs, frame_marker)
    if len(positions) < 2:
        print("âš  æœªæ‰¾åˆ°è¶³å¤Ÿå¸§æ ‡å¿—ï¼Œæ— æ³•æå–æ—¶é—´è½´ã€‚")
        return None, positions
    time_vals = []
    for pos in positions:
        ascii_part = srs[pos + 8 : pos + 16]
        val_str = ascii_part.decode(errors="ignore").strip()
        try:
            val = float(val_str)
        except ValueError:
            val = np.nan
        time_vals.append(val)
    time_vals = np.asarray(time_vals, dtype=float)
    finite = np.isfinite(time_vals)
    if not finite.any():
        print("âš  æœªè§£æå‡ºæœ‰æ•ˆæ—¶é—´å€¼ã€‚")
        return None, positions
    print(f"âœ… è§£ææ—¶é—´/ç”µä½ {finite.sum()} ç‚¹ï¼ŒèŒƒå›´: {time_vals[finite][0]:.4f} ~ {time_vals[finite][-1]:.4f}")
    return time_vals, positions


# ========= å…‰è°±çŸ©é˜µæå– =========
def extract_spectra_matrix(srs: bytes, frame_positions: list[int], max_frames=None):
    if len(frame_positions) < 2:
        print("âš  å¸§æ ‡è®°ä¸è¶³ï¼Œè·³è¿‡å…‰è°±å¯¼å‡ºã€‚")
        return None

    # è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
    first_gap = frame_positions[1] - frame_positions[0]
    if first_gap > 20000:
        payload_offset = 27854
        npts = 1024
        print(f"ğŸ” æ£€æµ‹åˆ°æ–°ç‰ˆ fast æ¨¡å¼ï¼Œä½¿ç”¨åç§» {payload_offset} å’Œ npts={npts}")
    else:
        payload_offset = 80
        npts = 600
        print(f"ğŸ” æ£€æµ‹åˆ°æ—§ç‰ˆ rapid æ¨¡å¼ï¼Œä½¿ç”¨åç§» {payload_offset}")

    # è®¡ç®—å¸§é—´è·ï¼ˆç”¨äºæ–°ç‰ˆï¼‰
    avg_gap = int(np.median(np.diff(frame_positions)))
    print(f"ğŸ§© ä¼°è®¡å¸§é—´è·: {avg_gap} bytes")

    frames = []
    filesize = len(srs)
    for i, pos in enumerate(frame_positions):
        if max_frames and i >= max_frames: 
            break
        start = pos + payload_offset
        end = start + npts * 4
        if end > filesize:
            break
        arr = np.frombuffer(srs[start:end], dtype=np.float32)
        if np.isfinite(arr).all() and np.std(arr) > 1e-6:
            frames.append(arr)

    if not frames:
        print("âš  æœªè§£æåˆ°å¸§æ•°æ®ã€‚")
        return None

    M = np.vstack(frames)
    print(f"âœ… å…‰è°±çŸ©é˜µå½¢çŠ¶: {M.shape} ï¼ˆè¡Œ=å¸§ï¼Œåˆ—=æ³¢æ•°ç‚¹ï¼‰")
    return M



# ========= èƒŒæ™¯å®šä½ä¸æå– =========
def detect_payloads_by_markers(srs: bytes, markers: list[dict], tol=64, min_sep=8000):
    votes = defaultdict(int)
    for m in markers:
        seq = bytes.fromhex(m["hex"])
        delta = int(m["delta_to_payload"])
        hits = find_all(srs, seq, max_hits=50000)
        for hp in hits:
            pos = hp + delta
            if 0 <= pos < len(srs):
                votes[pos] += 1
    if not votes:
        return []
    items = sorted(votes.items())
    merged = []
    cur_pos, cur_votes = None, 0
    for pos, v in items:
        if cur_pos is None:
            cur_pos, cur_votes = pos, v
        elif abs(pos - cur_pos) <= tol:
            cur_pos = int((cur_pos * cur_votes + pos * v) / (cur_votes + v))
            cur_votes += v
        else:
            merged.append((cur_pos, cur_votes))
            cur_pos, cur_votes = pos, v
    if cur_pos is not None:
        merged.append((cur_pos, cur_votes))
    merged.sort(key=lambda x: (-x[1], x[0]))
    picks = []
    for pos, _ in merged:
        if all(abs(pos - p) >= min_sep for p in picks):
            picks.append(pos)
        if len(picks) >= 4:
            break
    return sorted(picks)


def extract_background_matrix(srs: bytes, payload_offsets: list[int], target_npts: int):
    if not payload_offsets:
        print("âš  æœªèƒ½å®šä½èƒŒæ™¯ payloadã€‚")
        return None
    mats = []
    filesize = len(srs)
    for off in payload_offsets:
        npts = min((filesize - off) // 4, target_npts)
        a = np.frombuffer(srs, dtype=np.float32, count=npts, offset=off)
        if a.size == npts:
            mats.append(a)
    if not mats:
        print("âš  èƒŒæ™¯è¯»å–å¤±è´¥ã€‚")
        return None
    M = np.vstack(mats)
    print(f"âœ… èƒŒæ™¯çŸ©é˜µå½¢çŠ¶: {M.shape}")
    return M


# ========= ä¸»æµç¨‹ =========
def main():
    ap = argparse.ArgumentParser(description="ä» SRS æå–æ—¶é—´åˆ†è¾¨å…‰è°±ä¸èƒŒæ™¯ï¼ˆå«æ—¶é—´è½´ & è‡ªåŠ¨ç‚¹æ•°æ£€æµ‹ï¼‰")
    ap.add_argument("srs", help="SRS æ–‡ä»¶è·¯å¾„")
    ap.add_argument("--outdir", default="output", help="è¾“å‡ºç›®å½•")
    args = ap.parse_args()

    os.makedirs(args.outdir, exist_ok=True)
    srs = read_all_bytes(args.srs)
    marker = bytes.fromhex(FRAME_MARKER_HEX)

    print(f"æ–‡ä»¶å¤§å°: {len(srs):,} bytes")

    # 1ï¸âƒ£ æå–æ—¶é—´è½´ & å¸§ä½ç½®
    time_axis, frame_positions = extract_time_axis(srs, marker)
    if not frame_positions or len(frame_positions) < 2:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆå¸§æ ‡å¿—ï¼Œç»ˆæ­¢ã€‚")
        return

    # 2ï¸âƒ£ æ£€æµ‹ä¼ªå¸§ï¼ˆä¾‹å¦‚é¦–å¸§å¼‚å¸¸å¤§ï¼‰
    first_gap = frame_positions[1] - frame_positions[0]
    if first_gap > 20000:
        print(f"âš™ æ£€æµ‹åˆ°é¦–å¸§å¼‚å¸¸ï¼Œå·®è·={first_gap} bytesï¼Œè‡ªåŠ¨è·³è¿‡ç¬¬ 0 å¸§ã€‚")
        frame_positions = frame_positions[1:]
        if time_axis is not None and len(time_axis) > len(frame_positions):
            time_axis = time_axis[1:]

    # 3ï¸âƒ£ è‡ªåŠ¨ä¼°ç®—å¸§é—´è· & å…‰è°±ç‚¹æ•°
    frame_spacing = int(np.median(np.diff(frame_positions[:10]))) if len(frame_positions) > 10 else 3572
    header_offset = 80  # payload èµ·ç‚¹ï¼Œæ—§ç‰ˆä¸º 80
    npts_est = max(100, (frame_spacing - header_offset) // 4)

    print(f"ğŸ§© ä¼°è®¡å¸§é—´è·: {frame_spacing} bytes")
    print(f"ğŸ§© è‡ªåŠ¨æ¨ç®—æ¯å¸§å…‰è°±ç‚¹æ•° â‰ˆ {npts_est}")

    payload_offset = header_offset
    npts_guess = npts_est

    # 4ï¸âƒ£ æå–å…‰è°±çŸ©é˜µ
    spectra = []
    N = len(frame_positions) - 1
    for i in range(N):
        start = frame_positions[i]
        end = frame_positions[i + 1]
        if end <= start:
            continue
        block = srs[start + payload_offset:end-16]
        arr = np.frombuffer(block, dtype=np.float32)
        if arr.size >= npts_guess:
            arr = arr[:npts_guess]
        if np.isfinite(arr).any():
            spectra.append(arr)

    if not spectra:
        print("âš  æœªè§£æåˆ°å…‰è°±æ•°æ®ã€‚")
        return

    min_len = min(map(len, spectra))
    M = np.stack([f[:min_len] for f in spectra])
    print(f"âœ… å…‰è°±çŸ©é˜µå½¢çŠ¶: {M.shape} ï¼ˆè¡Œ=å¸§ï¼Œåˆ—=æ³¢æ•°ç‚¹ï¼‰")

    # 5ï¸âƒ£ ç”¨æˆ·è¾“å…¥æ³¢æ•°è½´
    try:
        start_wn = float(input("è¯·è¾“å…¥æ³¢æ•°èµ·ç‚¹ (cmâ»Â¹): ").strip())
        end_wn = float(input("è¯·è¾“å…¥æ³¢æ•°ç»ˆç‚¹ (cmâ»Â¹): ").strip())
    except Exception:
        print("âŒ æ³¢æ•°è¾“å…¥æ— æ•ˆï¼Œç»ˆæ­¢ã€‚")
        return
    wn_axis = np.linspace(start_wn, end_wn, M.shape[1])
    print(f"âœ… ç”Ÿæˆæ³¢æ•°è½´ [{wn_axis[0]:.3f} ~ {wn_axis[-1]:.3f}]  ç‚¹æ•°={len(wn_axis)}")

    # 6ï¸âƒ£ ä¿å­˜æ—¶é—´åˆ†è¾¨å…‰è°±
    out_ts = os.path.join(args.outdir, "spectra_timeseries.csv")
    if time_axis is not None and len(time_axis) >= M.shape[0]:
        data_with_time = np.column_stack((time_axis[: M.shape[0]], M))
        header = "time," + ",".join(f"{x:.6f}" for x in wn_axis)
        np.savetxt(out_ts, data_with_time, delimiter=",", header=header, comments="")
        print(f"ğŸ“„ å·²ä¿å­˜æ—¶é—´åˆ†è¾¨å…‰è°±: {out_ts}")
    else:
        header = ",".join(f"{x:.6f}" for x in wn_axis)
        np.savetxt(out_ts, M, delimiter=",", header=header, comments="")
        print(f"âš  æ—¶é—´è½´ä¸åŒ¹é…ï¼ŒæœªåŠ é¦–åˆ—ã€‚å·²ä¿å­˜: {out_ts}")

    # 7ï¸âƒ£ èƒŒæ™¯å®šä½
    bg_offsets = detect_payloads_by_markers(srs, BG_MARKERS)
    if not bg_offsets:
        print("æœªæ‰¾åˆ°èƒŒæ™¯æ ‡è®°ï¼Œå°è¯•æŒ‰é—´éš”æ¨æµ‹â€¦")
        first_guess = 0
        while first_guess < len(srs) - 10 * BG_INTERVAL_BYTES:
            arr = np.frombuffer(srs, dtype=np.float32, count=DEFAULT_POINTS, offset=first_guess)
            if np.isfinite(arr).all() and np.std(arr) > 1e-6:
                bg_offsets = [first_guess + i * BG_INTERVAL_BYTES for i in range(3)]
                break
            first_guess += 512

    if bg_offsets:
        print("å®šä½åˆ°èƒŒæ™¯ payload èµ·ç‚¹ï¼š")
        for i, p in enumerate(bg_offsets, 1):
            print(f"  BG#{i}  @SRS {p}")
    else:
        print("âš  æœªæ‰¾åˆ°èƒŒæ™¯æ ‡è®°ã€‚")

    # 8ï¸âƒ£ æå–èƒŒæ™¯çŸ©é˜µ
    bgM = extract_background_matrix(srs, bg_offsets, M.shape[1])
    if bgM is not None:
        out_bg = os.path.join(args.outdir, "background.csv")
        header = "wavenumber" + "".join([f",bg{i+1}" for i in range(bgM.shape[0])])
        out_mat = np.column_stack([wn_axis, bgM.T])
        np.savetxt(out_bg, out_mat, delimiter=",", header=header, comments="")
        print(f"ğŸ“„ å·²ä¿å­˜èƒŒæ™¯æ–‡ä»¶: {out_bg}")
    else:
        print("âš  æœªå¯¼å‡ºèƒŒæ™¯æ–‡ä»¶ã€‚")



if __name__ == "__main__":
    main()
